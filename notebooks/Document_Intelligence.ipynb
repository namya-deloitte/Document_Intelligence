{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14432d9",
   "metadata": {},
   "source": [
    "# **1. Imports and API keys/environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80891062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain==0.0.150 pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu jsonpickle\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6246cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d492868",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT2TokenizerFast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# parsed_pdf['content'] returns string \u001b[39;00m\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m parsed_pdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m---> 13\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2TokenizerFast\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_tokens\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mencode(text))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPT2TokenizerFast' is not defined"
     ]
    }
   ],
   "source": [
    "# Split by chunk\n",
    "\n",
    "# Step 1: Convert PDF to text\n",
    "from tika import parser  \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# opening pdf file\n",
    "parsed_pdf = parser.from_file(\"./Automate_the_Boring_Stuff_with_Python.pdf\")\n",
    "\n",
    "# parsed_pdf['content'] returns string \n",
    "data = parsed_pdf['content'] \n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 24,\n",
    "    length_function = count_tokens,)\n",
    "\n",
    "paragraphs = text_splitter.split_text(text=data)\n",
    "\n",
    "def clean_input(text: str):\n",
    "    cleaned_text = text.replace(\"\\n\",\"\").replace('..',\"\")\n",
    "    return cleaned_text\n",
    "cleaned_input = [clean_input(para) for para in paragraphs]\n",
    "\n",
    "chunks = text_splitter.create_documents([cleaned_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9de9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.Document"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9227304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick data visualization to ensure chunking was successful\n",
    "\n",
    "# Create a list of token counts\n",
    "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
    "print(len(token_counts))\n",
    "# Create a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Create a histogram of the token count distribution\n",
    "df.hist(bins=40, )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452cc1eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get embedding model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(embeddings)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create vector database\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# Get embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(embeddings)\n",
    "\n",
    "# Create vector database\n",
    "db = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e64b247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='• Leaves taken above the accrued number of leaves per month will be treated as negative leave balance. • Hasher can avail upto 10 days of negative privileged leaves (PL)  https://dna.hashedin.com/leaves/dashboard  • If an employee for any reason, needs to avail leave above his accrued limit and that in turn results in a negative leave balance, such leaves will be taken into consideration during emergency situations only. • The employee who has a negative leave balance must plan and manage to even out the negative to positive balance in the next 6 months.                 2.7 Other Types of Leave                     2.7.1 Leave under Maternity Benefit Act, 1961 • Female employees are eligible for maternity leave, as defined in the Maternity Benefit Act, up to a maximum of 26 weeks. • This is subject to the employee completing a minimum of 80 days service in the Company in the 12 months immediately preceding the date of expected delivery. Twenty-six weeks of ML may be availed at a stretch anytime during the term starting at eight weeks preceding the expected delivery date effective from 1st April 2017. • Under the Act, women employees are eligible for a maximum period of 26 weeks as Maternity Leave and this leave shall not be extended beyond a period of 1 month, without a certificate from a Qualified Medical Practitioner and approval of the HR Personnel. • The benefit is restricted up to a maximum of 2 deliveries. Post the birth of 2 children, 12 weeks of Maternity Leave is eligible • Commissioning Mother and Adoptive mothers can avail 12 weeks on Maternity leave from the date of adoption (newly added) • Maximum of 6 weeks leaves can be availed for miscarriage                      2.7.2 Extension of maternity leave • Maternity leave can be extended to a further 3 months, which will be approved on the discretion of', metadata={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"How many leaves can I take?\"\n",
    "docs = db.similarity_search(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31df8241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "\n",
    "query = \"What do you like about summer\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014946dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5d21f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the HashedIn chatbot! Type 'exit' to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996f1f0a2e343c4a3bb35011d0c036f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    chat_history = []\n",
    "\n",
    "    def on_submit(_):\n",
    "    \n",
    "        query = input_box.value\n",
    "        input_box.value = \"\"\n",
    "    \n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thank you for using this custom genai chatbot!\")\n",
    "            return\n",
    "    \n",
    "        result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        chat_history.append((query, result['answer']))\n",
    "    \n",
    "        display(widgets.HTML(f'<b>User:</b> {query}'))\n",
    "        display(widgets.HTML(f'<b><font color=\"teal\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
    "\n",
    "    print(\"Welcome to the HashedIn chatbot! Type 'exit' to stop.\")\n",
    "\n",
    "    input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "\n",
    "\n",
    "    input_box.on_submit(on_submit)\n",
    "\n",
    "    display(input_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6e59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5010e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DIMENSION = 1536 \n",
    "COLLECTION_NAME =\"data_db\"\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='Ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, description='Title texts', max_length=200),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields, description='Data collection')\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "index_params = {\n",
    "    'index_type': 'IVF_FLAT',\n",
    "    'metric_type': 'L2',\n",
    "    'params': {'nlist': 1024}\n",
    "}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d121107e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import jsonpickle\n",
    "def embed(text):\n",
    "    return openai.Embedding.create(\n",
    "        input=text, \n",
    "        engine='text-embedding-ada-002')[\"data\"][0][\"embedding\"]\n",
    "\n",
    "for idx, text in enumerate(random.sample(list(chunks), k=50)):\n",
    "    textJSON = jsonpickle.encode(text, unpicklable=False)\n",
    "    # Load COUNT amount of random values from dataset\n",
    "    # Insert the title id, the title text, and the title embedding vector\n",
    "  \n",
    "    ins=[[idx], [(textJSON[:198] +'..')if len(textJSON) > 200 else textJSON], [embed(textJSON)]]\n",
    "  \n",
    "    # Insert the title id, the title text, and the title embedding vector\n",
    "    collection.insert(ins)\n",
    "    time.sleep(3)  # Free OpenAI account limited to 60 RPM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ed37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d99a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [search], <MilvusException: (code=1, message=checkIfLoaded failed when search, collection:data_db, partitions:[], err = GetCollectionInfo failed, collection = data_db, err = collection 441594453568258088 has not been loaded to memory or load failed)>, <Time:{'RPC start': '2023-05-21 13:18:26.263971', 'RPC error': '2023-05-21 13:18:26.320932'}>\n"
     ]
    },
    {
     "ename": "MilvusException",
     "evalue": "<MilvusException: (code=1, message=checkIfLoaded failed when search, collection:data_db, partitions:[], err = GetCollectionInfo failed, collection = data_db, err = collection 441594453568258088 has not been loaded to memory or load failed)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     hit \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m     hit\u001b[38;5;241m.\u001b[39mentity\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mfind_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is your favourite season?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m                   \n",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m, in \u001b[0;36mfind_articles\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m      2\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m get_embedding(question)\n\u001b[0;32m      3\u001b[0m search_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnprobe\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43manns_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#output_fields=['title'], # we retrieve also the URL field!\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsistency_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStrong\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection working\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m hit \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\orm\\collection.py:612\u001b[0m, in \u001b[0;36mCollection.search\u001b[1;34m(self, data, anns_field, param, limit, expr, partition_names, output_fields, timeout, round_decimal, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataTypeNotMatchException(message\u001b[38;5;241m=\u001b[39mExceptionsMessage\u001b[38;5;241m.\u001b[39mExprType \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(expr))\n\u001b[0;32m    611\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m--> 612\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manns_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpartition_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_fields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_decimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_async\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\decorators.py:109\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m    108\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    111\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgRPC timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\decorators.py:105\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    107\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\decorators.py:136\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[1;32m--> 136\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\decorators.py:85\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         back_off \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(back_off \u001b[38;5;241m*\u001b[39m back_off_multiplier, max_back_off)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\decorators.py:50\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m# DEADLINE_EXCEEDED means that the task wat not completed\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# UNAVAILABLE means that the service is not reachable currently\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;66;03m# Reference: https://grpc.github.io/grpc/python/grpc.html#grpc-status-code\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;241m!=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mDEADLINE_EXCEEDED \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;241m!=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mUNAVAILABLE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\client\\grpc_handler.py:495\u001b[0m, in \u001b[0;36mGrpcHandler.search\u001b[1;34m(self, collection_name, data, anns_field, param, limit, expression, partition_names, output_fields, round_decimal, timeout, schema, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m requests \u001b[38;5;241m=\u001b[39m Prepare\u001b[38;5;241m.\u001b[39msearch_requests_with_expr(collection_name, data, anns_field, param, limit, schema,\n\u001b[0;32m    491\u001b[0m                                              expression, partition_names, output_fields, round_decimal,\n\u001b[0;32m    492\u001b[0m                                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m auto_id \u001b[38;5;241m=\u001b[39m schema[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_search_requests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_decimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_decimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\client\\grpc_handler.py:464\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search_requests\u001b[1;34m(self, requests, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_async\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, pre_err)\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pre_err\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymilvus\\client\\grpc_handler.py:455\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search_requests\u001b[1;34m(self, requests, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub\u001b[38;5;241m.\u001b[39mSearch(request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 455\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39merror_code, response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mreason)\n\u001b[0;32m    457\u001b[0m     raws\u001b[38;5;241m.\u001b[39mappend(response)\n\u001b[0;32m    458\u001b[0m round_decimal \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_decimal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mMilvusException\u001b[0m: <MilvusException: (code=1, message=checkIfLoaded failed when search, collection:data_db, partitions:[], err = GetCollectionInfo failed, collection = data_db, err = collection 441594453568258088 has not been loaded to memory or load failed)>"
     ]
    }
   ],
   "source": [
    "def find_articles(question):\n",
    "    query_embeddings = get_embedding(question)\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}, \"offset\": 0}\n",
    "\n",
    "    results = collection.search(\n",
    "        data=[query_embeddings],\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=3,\n",
    "        output_fields=[\"id\", \"title\"], \n",
    "        expr=None,\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "    print(\"Connection working\")\n",
    "    hit = results[0][0]\n",
    "    hit.entity.get('title')\n",
    "find_articles(\"What is your favourite season?\")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(question, markdown):\n",
    "    prompt = f\"\"\"Question: {question}\n",
    "Article:\n",
    "{markdown}\n",
    "\n",
    "###\n",
    "Does the given article contain all information required to answer the question? If not, return \"Answer: I don't know.\"\n",
    "\n",
    "If the article contains the answer, answer the question using the given article.\n",
    "Don't use your own knowledge. If the answer is not in the provided article text, return \"Answer: I don't know.\"\n",
    "Examples:\n",
    "---\n",
    "Answer: I don't know.\n",
    "---\n",
    "---\n",
    "Answer: here is the answer (one or two paragraphs)\n",
    "---\n",
    "\"\"\"\n",
    "    response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=200)\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_answer(question, summaries):\n",
    "    answers = \"\\n\".join(summaries)\n",
    "    prompt = f\"\"\"Question: {question}\n",
    "    Answers: {answers}\n",
    "\n",
    "    ###\n",
    "    Write a final answer to the question using the answers provided above.\n",
    "    If the answer is not in the provided answers, return \"Answer: I don't know.\"\n",
    "    If the provided answer does not answer the question, skip it.\n",
    "\"\"\"\n",
    "    response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=200)\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "\n",
    "def answer(question):\n",
    "    article_candidates = find_articles(question)\n",
    "    summaries = [article_candidates]\n",
    "    final_answer = get_final_answer(question, summaries)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae464f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
