{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14432d9",
   "metadata": {},
   "source": [
    "# **1. Imports and API keys/environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80891062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "#import tiktoken\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.vectorstores import Milvus\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredEmailLoader, CSVLoader, UnstructuredHTMLLoader, UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,ConversationSummaryMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca6246cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da3dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './Automate_the_Boring_Stuff_with_Python.pdf'\n",
    "filename, file_extension = os.path.splitext(file)\n",
    "\n",
    "def load_file(extension):\n",
    "    match extension:\n",
    "        case '.pdf':\n",
    "            return PyPDFLoader(file)\n",
    "        case '.txt':\n",
    "            return TextLoader(file)\n",
    "        case '.eml':\n",
    "            return UnstructuredEmailLoader(file)\n",
    "        case '.csv':\n",
    "            return CSVLoader(file)\n",
    "        case '.html':\n",
    "            return UnstructuredHTMLLoader(file)\n",
    "       \n",
    "        case default:\n",
    "            return UnstructuredFileLoader(file)\n",
    "\n",
    "# from langchain.indexes import VectorstoreIndexCreator\n",
    "loader = load_file(file_extension)\n",
    "# index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b75bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 24,\n",
    "    length_function = count_tokens)\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc7532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696618d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Configure the logging system\n",
    "# import logging\n",
    "# logging.basicConfig(filename ='app.log',\n",
    "#                         level = logging.ERROR)\n",
    "# logging.debug(vector_db = Milvus.from_documents(docs,embeddings,connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"}))\n",
    "\n",
    "# Create vector database\n",
    "vector_db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d492868",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_milvus = Milvus.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    ")\n",
    "\n",
    "print(\"Milvus database created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9227304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data visualization to display chunking and tokenization\n",
    "\n",
    "# Creating a list of token counts\n",
    "token_counts = [count_tokens(doc.page_content) for doc in docs]\n",
    "print(len(token_counts))\n",
    "# Creating a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Creating histogram of the token count distribution\n",
    "df.hist(bins=40, )\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e64b247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Part I\\nPython Progr Amming  \\nBAS iCS'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"What are the basics of python?\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31df8241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID efb332279159ac702d499c9dee342c9b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID efb332279159ac702d499c9dee342c9b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID efb332279159ac702d499c9dee342c9b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 10:33:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '6350', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149487', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '204ms', 'x-request-id': 'efb332279159ac702d499c9dee342c9b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbca4891aa926b5-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 76429e9dd564eb7aa26b7c84ba546a91 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 76429e9dd564eb7aa26b7c84ba546a91 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 76429e9dd564eb7aa26b7c84ba546a91 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 10:34:01 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-krejboal048jir8p64ktpzxt', 'openai-processing-ms': '295', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149487', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '204ms', 'x-request-id': '76429e9dd564eb7aa26b7c84ba546a91', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbca4dcfaa126b5-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f33017e44ccf31f8761f1a21e9ad7c40 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f33017e44ccf31f8761f1a21e9ad7c40 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f33017e44ccf31f8761f1a21e9ad7c40 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 10:34:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '149', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149487', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '204ms', 'x-request-id': 'f33017e44ccf31f8761f1a21e9ad7c40', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbca4fccfe126b5-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Regex (or regular expressions) are a way of searching for patterns in strings in Python. To use regex in Python, you must first import the regex module with import re. Then, you create a Regex object with the re.compile() function. You can then pass the string you want to search into the Regex object's search() method. This returns a Match object. Finally, you can call the Match object's group() method to return a string of the actual matched text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 36f9a706bfd912f57d849457648acb29 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 36f9a706bfd912f57d849457648acb29 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 36f9a706bfd912f57d849457648acb29 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 10:34:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-krejboal048jir8p64ktpzxt', 'openai-processing-ms': '209', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '2', 'x-ratelimit-remaining-tokens': '39912', 'x-ratelimit-reset-requests': '20s', 'x-ratelimit-reset-tokens': '132ms', 'x-request-id': '36f9a706bfd912f57d849457648acb29', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbca53b3ce826b5-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Python is a high-level programming language that is widely used for web development, scientific computing, data analysis, artificial intelligence, and many other applications. It was first released in 1991 by Guido van Rossum and has since become one of the most popular programming languages in the world. Python is known for its simplicity, readability, and ease of use, making it a great choice for beginners and experienced programmers alike. It has a large and active community of developers who contribute to its development and create libraries and tools that make it even more powerful and versatile.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
    "\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "\n",
    "query = \"Explain regex in python\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "\n",
    "print(chain.run(input_documents=docs, question=query))\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    openai_api_key=\"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\")\n",
    "        \n",
    "conversation_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation_buffer.run(\"What is python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_summary = ConversationChain(\n",
    "llm = llm,\n",
    "memory = ConversationSummaryMemory(llm=llm) )\n",
    "\n",
    "conversation_summary.run(\"What is python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06995004",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_summary.run(\"Summarize the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6ca9b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the docs\n",
      "Initialised the chain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAutomate the Boring Stuff with Python is a book written by Al Sweigart that provides step-by-step instructions on how to use Python to automate tedious tasks. It covers topics such as flow control, functions, lists, dictionaries, strings, regular expressions, file handling, debugging, web scraping, Excel spreadsheets, PDF and Word documents, CSV files, JSON data, time, scheduling tasks, launching programs, sending emails and text messages, manipulating images, controlling the keyboard and mouse, data structuring, and more. It also provides practice questions and projects related to each data type, as well as examples of programs and projects that can be created with Python.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(\"Loaded the docs\")\n",
    "llm = OpenAI(temperature=0, model_name = \"text-davinci-003\", top_p =1)\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "print(\"Initialised the chain\")\n",
    "chain.run(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "014946dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), vector_db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c5d21f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the HashedIn chatbot! Type 'exit' to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c85e8336a9648e9b166996dd427e317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991b3796d8004b89a6bc1ef1957d1dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b> User:</b> How do I load a CSV file?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0f8d76c8494278b72896caf4f7e9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"teal\"> Chatbot:</font></b>  To read a CSV file with the csv module, first open it …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using this custom GenAI chatbot!\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    chat_history = []\n",
    "\n",
    "    def on_submit(_):\n",
    "        query = input_box.value\n",
    "        input_box.value = \"\"\n",
    "    \n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thank you for using this custom GenAI chatbot!\")\n",
    "            return\n",
    "    \n",
    "        result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        chat_history.append((query, result['answer']))\n",
    "    \n",
    "        display(widgets.HTML(f'<b> User:</b> {query}'))\n",
    "        display(widgets.HTML(f'<b><font color=\"teal\"> Chatbot:</font></b> {result[\"answer\"]}'))\n",
    "\n",
    "    print(\"Welcome to the HashedIn chatbot! Type 'exit' to stop.\")\n",
    "\n",
    "    input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "\n",
    "\n",
    "    input_box.on_submit(on_submit)\n",
    "\n",
    "    display(input_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f6e59a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('204   Chapter 9since a ZIP file can also contain multiple files and \\n'\n",
      " 'subfolders, it’s a handy way to package several files into one. This single '\n",
      " 'file, called an archive file , can \\n'\n",
      " 'then be, say, attached to an email. \\n'\n",
      " 'Your Python programs can both create \\n'\n",
      " 'and open (or extract ) ZIP files using functions \\n'\n",
      " 'in the \\n'\n",
      " 'zipfile  module. Say you have a ZIP file \\n'\n",
      " 'named example.zip  that has the contents shown \\n'\n",
      " 'in Figure  9-2.\\n'\n",
      " 'You can downl\\n'\n",
      " 'oad this ZIP file from http://  \\n'\n",
      " 'nostarch.com/au\\n'\n",
      " 'tomatestuff/  or just follow along \\n'\n",
      " 'using a ZIP file already on your computer.\\n'\n",
      " 'Reading ZIP Files\\n'\n",
      " 'To read the contents of a ZIP file, first you must create a ZipFile  '\n",
      " 'object \\n'\n",
      " '(note  the capital lette\\n'\n",
      " 'rs Z and F ). ZipFile  objects are conceptually similar \\n'\n",
      " 'to the File objects you saw returned by the open()  function in the '\n",
      " 'previous \\n'\n",
      " 'chapter: They are values through which the program interacts with the file. '\n",
      " 'To \\n'\n",
      " ' create a ZipFile  object, call the zipfile.ZipFile()  function, passing it '\n",
      " 'a \\n'\n",
      " 'string of the .zip  file’s filename. Note that zipfile  is the name of the '\n",
      " 'Python \\n'\n",
      " 'module, and ZipFile()  is the name of the function.\\n'\n",
      " 'For example, enter the following into the interactive shell:\\n'\n",
      " '>>> import zipfile, os\\n'\n",
      " \">>> os.chdir('C:\\\\\\\\')    # move to the folder with example.zip>>> \"\n",
      " \"exampleZip = zipfile.ZipFile('example.zip')>>> \"\n",
      " \"exampleZip.namelist()['spam.txt', 'cats/', 'cats/catnames.txt', \"\n",
      " \"'cats/zophie.jpg']>>> spamInfo = exampleZip.getinfo('spam.txt')>>> \"\n",
      " 'spamInfo.file_size13908>>> spamInfo.compress_size3828\\n'\n",
      " \"u >>> 'Compressed file is %sx smaller!' % (round(spamInfo.file_size / \"\n",
      " 'spamInfo\\n'\n",
      " \".compress_size, 2))'Compressed file is 3.63x smaller!'>>> \"\n",
      " 'exampleZip.close()\\n'\n",
      " 'A ZipFile  object has a namelist()  method that returns a list of strings')\n",
      "\n",
      "Similarity score:  0.36144015\n"
     ]
    }
   ],
   "source": [
    "# Finds relevant data along with a similarity score\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "query = \"Which files have a .zip extension?\"\n",
    "docs = vector_db.similarity_search_with_score(query)\n",
    "pp.pprint(docs[0][0].page_content)\n",
    "print(\"\\nSimilarity score: \",docs[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5010e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,CrossEncoder,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d121107e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b33ef6ddad46d79a8b74e045b64995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3038d722b6b844df87a8d71a34f2255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61270d2ae14b43c78e6c070fe4abf9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf922a12316d41d5b70db3b1cc5348d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c158a93ae15d4bdf94f01efdcad7378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b525b10344a9aba3afd1ee4bd99d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780af6878e374656ba929f2a864d5323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8aaf4764a24a6185486f25d99dd9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1f848c46b54ee487e8232c674aad74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097156c861c747b498d736f9ef13ffc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c90152f4ea41cb83c1fd6eccee5c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407624224c414ce4b6eadd081e7f8526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160827a659a14420b30dd33c34de4151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493b3f227d0749bb9b48dde46f3f7a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_vector = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model_encoder = CrossEncoder(\"cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1ed37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3803b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list=[]\n",
    "for doc in docs:\n",
    "    docs_list.append(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63d99a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embeddings = model_vector.encode(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57fbc7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 384)\n"
     ]
    }
   ],
   "source": [
    "# indexing of the embeddings\n",
    "index = faiss.IndexFlatIP(hf_embeddings.shape[1])\n",
    "index.train(hf_embeddings)\n",
    "index.add(hf_embeddings)\n",
    "\n",
    "print(hf_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40dc58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def token_count(string):\n",
    "    encoding = tiktoken.get_encoding(\"p50k_base\")\n",
    "    num_tokens = len(encoding.encode(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6cf29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you? How do I write a class in python?\n",
      "similarity score: [ 1.2462821 -1.7051373 -2.73224   -3.8657386 -2.7719178 -2.580507\n",
      " -2.6859431 -3.737011   3.3715975 -4.1505437]\n",
      "('3.37\\tReading and Writing Files    183Note that each of the string values '\n",
      " 'ends with a newline character, \\\\n , \\n'\n",
      " 'except for the last line of the file. A list of strings is often easier to '\n",
      " 'work with \\n'\n",
      " 'than a single large string value.\\n'\n",
      " 'Writing to Files\\n'\n",
      " 'Python allows you to write content to a file in a way similar to how the '\n",
      " 'print()  \\n'\n",
      " 'function “writes” strings to the screen. You can’t write to a file you’ve '\n",
      " 'opened in read mode, though. Instead, you need to open it in “write '\n",
      " 'plaintext” mode or “append plaintext” mode, or write mode and append mode  '\n",
      " 'for short.\\n'\n",
      " 'Write mode will overwrite the existing file and start from scratch, just \\n'\n",
      " 'like when you overwrite a variable’s value with a new value. Pass \\n'\n",
      " \"'w' as the \\n\"\n",
      " 'second argument to open()  to open the file in write mode. Append mode, \\n'\n",
      " 'on the other hand, will append text to the end of the existing file. You can '\n",
      " 'think of this as appending to a list in a variable, rather than overwriting '\n",
      " 'the variable altogether. Pass \\n'\n",
      " \"'a' as the second argument to open()  to open the \\n\"\n",
      " 'file in append mode.\\n'\n",
      " 'If the filename passed to open()  does not exist, both write and append \\n'\n",
      " 'mode will create a new, blank file. After reading or writing a file, call '\n",
      " 'the \\n'\n",
      " 'close()  method before opening the file again.\\n'\n",
      " 'Let’s put these concepts together. Enter the following into the inter -\\n'\n",
      " 'active shell:\\n'\n",
      " \">>> baconFile = open('bacon.txt', 'w')   \\n\"\n",
      " \">>> baconFile.write('Hello world!\\\\n')13>>> baconFile.close()>>> baconFile = \"\n",
      " \"open('bacon.txt', 'a') >>> baconFile.write('Bacon is not a vegetable.')25>>> \"\n",
      " \"baconFile.close()>>> baconFile = open('bacon.txt')>>> content = \"\n",
      " 'baconFile.read()>>> baconFile.close()>>> print(content)Hello world!Bacon is '\n",
      " 'not a vegetable.\\n'\n",
      " 'First, we open bacon.txt  in write mode. Since there isn’t a bacon.txt  '\n",
      " 'yet, \\n'\n",
      " 'Python creates one. Calling write()  on the opened file and passing write()')\n",
      "8\n",
      "********************************************\n",
      "('1.25\\tLists   97If you have only one value in your tuple, you can indicate '\n",
      " 'this by placing \\n'\n",
      " 'a trailing comma after the value inside the parentheses. Otherwise, Python \\n'\n",
      " 'will think you’ve just typed a value inside regular parentheses. The comma '\n",
      " 'is what lets Python know this is a tuple value. (Unlike some other '\n",
      " 'program-ming languages, in Python it’s fine to have a trailing comma after '\n",
      " 'the last item in a list or tuple.) Enter the following \\n'\n",
      " 'type()  function calls into the \\n'\n",
      " 'interactive shell to see the distinction:\\n'\n",
      " \">>> type(('hello',))\\n\"\n",
      " \"<class 'tuple'>>>> type(('hello'))<class 'str'>\\n\"\n",
      " 'You can use tuples to convey to anyone reading your code that you \\n'\n",
      " 'don’t intend for that sequence of values to change. If you need an ordered \\n'\n",
      " 'sequence of values that never changes, use a tuple. A second benefit of '\n",
      " 'using tuples instead of lists is that, because they are immutable and their '\n",
      " 'contents don’t change, Python can implement some optimizations that make '\n",
      " 'code using tuples slightly faster than code using lists.\\n'\n",
      " 'Converting Types with the list() and tuple() Functions\\n'\n",
      " \"Just like how str(42)  will return '42', the string representation of the \"\n",
      " 'inte -\\n'\n",
      " 'ger 42, the functions list()  and tuple()  will return list and tuple '\n",
      " 'versions \\n'\n",
      " 'of the values passed to them. Enter the following into the interactive '\n",
      " 'shell, and notice that the return value is of a different data type than the '\n",
      " 'value passed:\\n'\n",
      " \">>> tuple(['cat', 'dog', 5])\\n\"\n",
      " \"('cat', 'dog', 5)>>> list(('cat', 'dog', 5))['cat', 'dog', 5]>>> \"\n",
      " \"list('hello')['h', 'e', 'l', 'l', 'o']\\n\"\n",
      " 'Converting a tuple to a list is handy if you need a mutable version of a \\n'\n",
      " 'tuple value.\\n'\n",
      " 'references\\n'\n",
      " 'As you’ve seen, variables store strings and integer values. Enter the '\n",
      " 'follow-\\n'\n",
      " 'ing into the interactive shell:\\n'\n",
      " '>>> spam = 42\\n'\n",
      " '>>> cheese = spam>>> spam = 100>>> spam100>>> cheese42')\n",
      "0\n",
      "********************************************\n",
      "('-1.71\\tPython Basics    23Comments\\n'\n",
      " 'The following line is called a comment . \\n'\n",
      " 'u # This program says hello and asks for my name.\\n'\n",
      " 'Python ignores comments, and you can use them to write notes or \\n'\n",
      " 'remind yourself what the code is trying to do. Any text for the rest of '\n",
      " 'the \\n'\n",
      " 'line following a hash mark ( #) is part of a comment. \\n'\n",
      " 'Sometimes, programmers will put a # in front of a line of code to tem-\\n'\n",
      " 'porarily remove it while testing a program. This is called commenting out '\n",
      " 'code, and it can be useful when you’re trying to figure out why a program '\n",
      " 'doesn’t work. You can remove the \\n'\n",
      " '# later when you are ready to put the line \\n'\n",
      " 'back in.\\n'\n",
      " 'Python also ignores the blank line after the comment. You can add as \\n'\n",
      " 'many blank lines to your program as you want. This can make your code easier '\n",
      " 'to read, like paragraphs in a book.\\n'\n",
      " 'The print()  Function\\n'\n",
      " 'The print()  function displays the string value inside the parentheses on '\n",
      " 'the \\n'\n",
      " 'screen. \\n'\n",
      " \"v print('Hello world!')\\n\"\n",
      " \"print('What is your name?') # ask for their name\\n\"\n",
      " \"The line print('Hello world!')  means “Print out the text in the string \\n\"\n",
      " \"'Hello world!' .” When Python executes this line, you say that Python is \\n\"\n",
      " 'calling the print()  function and the string value is being passed  to the '\n",
      " 'func -\\n'\n",
      " 'tion. A value that is passed to a function call is an argument . Notice '\n",
      " 'that \\n'\n",
      " 'the quotes are not printed to the screen. They just mark where the string '\n",
      " 'begins and ends; they are not part of the string value. \\n'\n",
      " 'note You can also use this function to put a blank line on the screen; just '\n",
      " 'call print()  with \\n'\n",
      " 'nothing in between the parentheses.\\n'\n",
      " 'When writing a function name, the opening and closing parentheses at \\n'\n",
      " 'the end identify it as the name of a function. This is why in this book '\n",
      " 'you’ll see \\n'\n",
      " 'print()  rather than print . Chapter 2 describes functions in more detail.\\n'\n",
      " 'The input()  Function\\n'\n",
      " 'The input()  function waits for the user to type some text on the keyboard \\n'\n",
      " 'and press enter . \\n'\n",
      " 'w myName = input()\\n'\n",
      " 'This function call evaluates to a string equal to the user’s text, and the')\n",
      "1\n",
      "********************************************\n",
      "(\"-2.58\\t28   Chapter 1print('You will be ' + str(int(myAge) + 1) + ' in a \"\n",
      " \"year.')\\n\"\n",
      " \"print('You will be ' + str(int(     ) + 1) + ' in a year.')\\n\"\n",
      " \"print('You will be ' + str(              ) + ' in a year.')print('You will \"\n",
      " \"be ' + str(              ) + ' in a year.')print('You will be ' \"\n",
      " \"+                     + ' in a year.')'4'\\n\"\n",
      " \"'5'\\n\"\n",
      " \"print('You will be 5'                      + ' in a year.')print('You will \"\n",
      " \"be 5 in a year.')54 + 1\\n\"\n",
      " 'Figure 1-4: The evaluation steps, if 4 was stored in myAge\\n'\n",
      " 'Summary\\n'\n",
      " 'You can compute expressions with a calculator or type string concatena -\\n'\n",
      " 'tions with a word processor. You can even do string replication easily by \\n'\n",
      " 'copying and pasting text. But expressions, and their component '\n",
      " 'values—operators, variables, and function calls—are the basic building '\n",
      " 'blocks that make programs. Once you know how to handle these elements, you '\n",
      " 'will be able to instruct Python to operate on large amounts of data for '\n",
      " 'you.\\n'\n",
      " 'It is good to remember the different types of operators (\\n'\n",
      " '+, -, *, /, //, %, \\n'\n",
      " 'and ** for math operations, and + and * for string operations) and the '\n",
      " 'three \\n'\n",
      " 'data types (integers, floating-point numbers, and strings) introduced in '\n",
      " 'this chapter.\\n'\n",
      " 'A few different functions were introduced as well. The \\n'\n",
      " 'print()  and input()  \\n'\n",
      " 'functions handle simple text output (to the screen) and input (from the key '\n",
      " '-\\n'\n",
      " 'board). The len()  function takes a string and evaluates to an int of the '\n",
      " 'num-\\n'\n",
      " 'ber of characters in the string. The str() , int() , and float()  functions '\n",
      " 'will \\n'\n",
      " 'evaluate to the string, integer, or floating-point number form of the value '\n",
      " 'they are passed.\\n'\n",
      " 'In the next chapter, you will learn how to tell Python to make intelli-')\n",
      "5\n",
      "********************************************\n",
      "(\"-2.69\\t>>> batRegex = re.compile(r'Bat(wo)+man')\\n\"\n",
      " \">>> mo1 = batRegex.search('The Adventures of Batwoman')>>> \"\n",
      " \"mo1.group()'Batwoman'\\n\"\n",
      " \">>> mo2 = batRegex.search('The Adventures of Batwowowowoman')\\n\"\n",
      " \">>> mo2.group()'Batwowowowoman'\")\n",
      "6\n",
      "********************************************\n",
      "('-2.73\\tFlow Control    573\\n'\n",
      " '210\\n'\n",
      " 'importing modules\\n'\n",
      " 'All Python programs can call a basic set of functions called built-in  '\n",
      " 'functions , \\n'\n",
      " 'includi\\n'\n",
      " 'ng the print() , input() , and len()  functions you’ve seen before. Python \\n'\n",
      " 'also comes with a set of modules called the standard library. Each module \\n'\n",
      " 'is a Python program that contains a related group of functions that can be '\n",
      " 'embedded in your programs. For example, the \\n'\n",
      " 'math module has mathematics-  \\n'\n",
      " 'related functions, the random  module has random number–related functions, \\n'\n",
      " 'and so on.\\n'\n",
      " 'Before you can use the functions in a module, you must import the \\n'\n",
      " 'module with an import  statement. In code, an import  statement consists '\n",
      " 'of \\n'\n",
      " 'the following:\\n'\n",
      " '•\\tThe import  keyword\\n'\n",
      " '•\\tThe name of the module\\n'\n",
      " '•\\tOptionally, more module names, as long as they are separated by \\n'\n",
      " 'commas\\n'\n",
      " 'Once you import a module, you can use all the cool functions of that \\n'\n",
      " 'module. Let’s give it a try with the random  module, which will give us '\n",
      " 'access \\n'\n",
      " 'to the random.ranint()  function.\\n'\n",
      " 'Enter this code into the file editor, and save it as printRandom.py :\\n'\n",
      " 'import random\\n'\n",
      " 'for i in range(5):    print(random.randint(1, 10))\\n'\n",
      " 'When you run this program, the output will look something like this:\\n'\n",
      " '41841\\n'\n",
      " 'The random.randint()  function call evaluates to a random integer value \\n'\n",
      " 'between the two integers that you pass it. Since randint()  is in the '\n",
      " 'random  \\n'\n",
      " 'module, you must first type random.  in front of the function name to tell \\n'\n",
      " 'Python to look for this function inside the random  module. \\n'\n",
      " 'Here’s an example of an import  statement that imports four different \\n'\n",
      " 'modules:\\n'\n",
      " 'import random, sys, os, math')\n",
      "2\n",
      "********************************************\n",
      "('-2.77\\tFunctions   71 def ham():\\n'\n",
      " 'w     print(eggs) # this is the global\\n'\n",
      " '    \\n'\n",
      " ' eggs = 42 # this is the global spam() print(eggs)\\n'\n",
      " 'In the spam()  function, eggs is the global eggs variable, because there’s \\n'\n",
      " 'a global  statement for eggs at the beginning of the function u . In bacon() '\n",
      " ', \\n'\n",
      " 'eggs is a local variable, because there’s an assignment statement for it '\n",
      " 'in \\n'\n",
      " 'that function v . In ham()  w, eggs is the global variable, because there is '\n",
      " 'no \\n'\n",
      " 'assignment statement or global  statement for it in that function. If you '\n",
      " 'run \\n'\n",
      " ' sameName3.py , the ou\\n'\n",
      " 'tput will look like this:\\n'\n",
      " 'spam\\n'\n",
      " 'In a function, a variable will either always be global or always be local. \\n'\n",
      " 'There’s no way that the code in a function can use a local variable named \\n'\n",
      " 'eggs and then later in that same function use the global eggs variable.\\n'\n",
      " 'note  If you ever want to modify the value stored in a global variable from '\n",
      " 'in a function, \\n'\n",
      " 'you must use a global  statement on that variable.\\n'\n",
      " 'If you try to use a local variable in a function before you assign a value \\n'\n",
      " 'to it, as in the following program, Python will give you an error. To see '\n",
      " 'this, type the following into the file editor and save it as sameName4.py :\\n'\n",
      " 'def spam():\\n'\n",
      " '    print(eggs) # ERROR!\\n'\n",
      " \"u     eggs = 'spam local'\\n\"\n",
      " '    \\n'\n",
      " \"v eggs = 'global'\\n\"\n",
      " 'spam()\\n'\n",
      " 'If you run the previous program, it produces an error message. \\n'\n",
      " 'Traceback (most recent call last):  File \"C:/test3784.py\", line 6, in '\n",
      " '<module>    spam()  File \"C:/test3784.py\", line 2, in spam    print(eggs) # '\n",
      " \"ERROR!UnboundLocalError: local variable 'eggs' referenced before assignment\\n\"\n",
      " 'This error happens because Python sees that there is an assignment \\n'\n",
      " 'statement for eggs in the spam()  function u and therefore considers eggs '\n",
      " 'to \\n'\n",
      " 'be local. But because print(eggs)  is executed before eggs is assigned any -')\n",
      "4\n",
      "********************************************\n",
      "('-3.74\\tfile and save it as threadDemo.py :\\n'\n",
      " 'import threading, time\\n'\n",
      " \"print('Start of program.')\\n\"\n",
      " 'u def takeANap():\\n'\n",
      " \"    time.sleep(5)    print('Wake up!')\\n\"\n",
      " 'v threadObj = threading.Thread(target=takeANap)w threadObj.start()\\n'\n",
      " \"print('End of program.')\")\n",
      "7\n",
      "********************************************\n",
      "('-3.87\\tDictionaries and Structuring Data    115Figure 5-5: Player O wins.\\n'\n",
      " 'Of course, the player sees only what is printed to the screen, not the \\n'\n",
      " 'contents of variables. Let’s create a function to print the board '\n",
      " 'dictionary \\n'\n",
      " 'onto the screen. Make the following addition to ticTacToe.py  (new code is '\n",
      " 'in \\n'\n",
      " 'bold):\\n'\n",
      " \"theBoard = {'top-L': ' ', 'top-M': ' ', 'top-R': ' ',\\n\"\n",
      " \"            'mid-L': ' ', 'mid-M': ' ', 'mid-R': ' ',            'low-L': ' \"\n",
      " \"', 'low-M': ' ', 'low-R': ' '}def printBoard(board):    print(board['top-L'] \"\n",
      " \"+ '|' + board['top-M'] + '|' + board['top-R'])    print('-+-+-')    \"\n",
      " \"print(board['mid-L'] + '|' + board['mid-M'] + '|' + board['mid-R'])    \"\n",
      " \"print('-+-+-')    print(board['low-L'] + '|' + board['low-M'] + '|' + \"\n",
      " \"board['low-R'])printBoard(theBoard)\\n\"\n",
      " 'When you run this program, printBoard()  will print out a blank tic-tac-\\n'\n",
      " 'toe board.\\n'\n",
      " ' | |-+-+- | |-+-+- | |\\n'\n",
      " 'The printBoard()  function can handle any tic-tac-toe data structure you \\n'\n",
      " 'pass it. Try changing the code to the following:\\n'\n",
      " \"theBoard = {'top-L': 'O', 'top-M': 'O', 'top-R': 'O', 'mid-L': 'X', 'mid-M': \"\n",
      " \"'X', 'mid-R': ' ', 'low-L': ' ', 'low-M': ' ', 'low-R': 'X'}\\n\"\n",
      " 'def printBoard(board):')\n",
      "3\n",
      "********************************************\n",
      "('-4.15\\tIntroduction   5Programming Is a Creative Activity\\n'\n",
      " 'Programming is a creative task, somewhat like constructing a castle out \\n'\n",
      " 'of LEGO bricks. You start w\\n'\n",
      " 'ith a basic idea of what you want your castle \\n'\n",
      " 'to look like and invento\\n'\n",
      " 'ry your available blocks. Then you start building. \\n'\n",
      " 'Once you’ve finished building your program, you can pretty up your code just '\n",
      " 'like you would your castle. \\n'\n",
      " 'The difference between programming and other creative activities is \\n'\n",
      " 'that when programming, you have all the raw materials you need in your '\n",
      " 'computer; you don’t need to buy any additional canvas, paint, film, yarn, '\n",
      " 'LEGO bricks, or electronic components. When your program is written, it can '\n",
      " 'easily be shared online with the entire world. And though you’ll make '\n",
      " 'mistakes when programming, the activity is still a lot of fun.\\n'\n",
      " 'About this Book\\n'\n",
      " 'The first part of this book covers basic Python programming concepts, and '\n",
      " 'the second part covers various tasks you can have your computer automate. '\n",
      " 'Each chapter in the second part has project programs for you to study. '\n",
      " 'Here’s a brief rundown of what you’ll find in each chapter:\\n'\n",
      " 'Part I: Python P rogramming Basics\\n'\n",
      " 'Chapter 1: Python Basics\\n'\n",
      " ' Covers expressions\\n'\n",
      " ', the most basic type of \\n'\n",
      " 'Python instruction, and how to use the Python interactive shell soft-\\n'\n",
      " 'ware to experiment with code.\\n'\n",
      " 'Chapter 2: Flow Control  Explains how to make pro\\n'\n",
      " 'grams decide \\n'\n",
      " 'which instructions to execute so your code can intelligently respond to \\n'\n",
      " 'different conditions.\\n'\n",
      " 'Chapter 3: Functions  Instructs you on how to d\\n'\n",
      " 'efine your own func-\\n'\n",
      " 'tions so that you can organize your code into more manageable chunks.Chapter '\n",
      " '4: Lists\\n'\n",
      " ' Introduces the list da\\n'\n",
      " 'ta type and explains how to \\n'\n",
      " 'organize data.Chapter 5: Dictionaries and Structuring Data\\n'\n",
      " ' Introduces the dicti\\n'\n",
      " 'on-\\n'\n",
      " 'ary data type and shows you more powerful ways to organize data.Chapter 6: '\n",
      " 'Manipulating Strings\\n'\n",
      " ' Covers working with t\\n'\n",
      " 'ext data \\n'\n",
      " '(called strings  in Python). \\n'\n",
      " 'Part II: Automating Tasks\\n'\n",
      " 'Chapter 7: Pattern Matching with Regular Expressions  Covers how \\n'\n",
      " 'Python can m\\n'\n",
      " 'anipulate strings and search for text patterns with regular \\n'\n",
      " 'expressions.Chapter 8: Reading and Writing Files\\n'\n",
      " ' Explains how your prog\\n'\n",
      " 'rams')\n",
      "9\n",
      "********************************************\n",
      "Refined Prompt: \n",
      "    Answer the question based on the contexts below. \n",
      "    If the question cannot be answered using the information \n",
      "    provided answer with \"I don't know\".\n",
      "\n",
      "    ###\n",
      "\n",
      "    Contexts:\n",
      "    Python refers to the Python programming language (with syntax rules for\n",
      "                        writing what is considered valid Python code) and the Python interpreter\n",
      "                        software that reads source code (written in the Python language) and performs\n",
      "                        its instructions.The first part of this book covers basic Python programming concepts, and\n",
      "                        the second part covers various tasks you can have your computer automate.\n",
      "\n",
      "    ###\n",
      "\n",
      "    Question:How do I write a class in python?\n",
      "    Answer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you? \n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.) {\n  \"error\": {\n    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 13:44:45 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '119', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '248975', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '245ms', 'x-request-id': 'a93acd69f9ca212aee938df4b66f1647', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbdbc42df381d8d-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefined Prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrefined_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#Feed input prompt to openai model\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefined_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m#print response from openai model\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mAnswer from text-davinci-003: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAPIError\u001b[0m: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.) {\n  \"error\": {\n    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a93acd69f9ca212aee938df4b66f1647 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 13:44:45 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '119', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '248975', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '245ms', 'x-request-id': 'a93acd69f9ca212aee938df4b66f1647', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbdbc42df381d8d-BLR', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "while True:\n",
    "    # Ask me a query!\n",
    "    query = input(\"How can I assist you? \")\n",
    "    \n",
    "    if not query:\n",
    "        break\n",
    "        \n",
    "    #create the query vector to obtain the relevant index\n",
    "    query_vector = model_vector.encode([query])\n",
    "    D,I = index.search(query_vector, k)\n",
    "    relevant_indexes = I.tolist()[0]\n",
    "\n",
    "    # obtain the respective data chunks\n",
    "    data_chunks = []\n",
    "    for i in relevant_indexes:\n",
    "        data_chunks.append(docs_list[i])\n",
    "\n",
    "    #calculate similarity scores to rank paragraphs\n",
    "    query_paras_combined = [[query, para] for para in data_chunks]\n",
    "    similarity_scores = model_encoder.predict(query_paras_combined)\n",
    "    sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
    "    \n",
    "    \n",
    "    print(f\"similarity score: {similarity_scores}\")\n",
    "    for idx in sim_scores_argsort:\n",
    "        pp.pprint(\"{:.2f}\\t{}\".format(similarity_scores[idx], data_chunks[idx]))\n",
    "        print(idx)\n",
    "        print('********************************************')\n",
    "    #sort indexes based on scores\n",
    "    \n",
    "\n",
    "    #build context -- max paragraphs allowed in context is set to 3 and max token length is set to 2700\n",
    "    relevant_context =  \"\"\"Python refers to the Python programming language (with syntax rules for\n",
    "                        writing what is considered valid Python code) and the Python interpreter\n",
    "                        software that reads source code (written in the Python language) and performs\n",
    "                        its instructions.The first part of this book covers basic Python programming concepts, and\n",
    "                        the second part covers various tasks you can have your computer automate.\"\"\"\n",
    "    threshold = 3       \n",
    "    for idx in sim_scores_argsort:\n",
    "        if threshold > 0 and token_count(relevant_context)!=None and token_count(relevant_context)+token_count(relevant_paras[idx])<2700:\n",
    "            relevant_context += relevant_paras[idx] + \"\\n\\n\"\n",
    "            threshold = threshold - 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #generate an input prompt\n",
    "    refined_prompt = f\"\"\"\n",
    "    Answer the question based on the contexts below. \n",
    "    If the question cannot be answered using the information \n",
    "    provided answer with \"I don't know\".\n",
    "\n",
    "    ###\n",
    "\n",
    "    Contexts:\n",
    "    {relevant_context}\n",
    "\n",
    "    ###\n",
    "\n",
    "    Question:{query}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    print(f\"Refined Prompt: {refined_prompt}\")\n",
    "\n",
    "#Feed input prompt to openai model\n",
    "response = openai.Completion.create(\n",
    "engine=\"text-davinci-003\",\n",
    "prompt=refined_prompt,\n",
    "temperature=0.0,\n",
    "max_tokens=1024,\n",
    "top_p=1,\n",
    "frequency_penalty=0,\n",
    "presence_penalty=0\n",
    "    )\n",
    "\n",
    "#print response from openai model\n",
    "print(f\"\"\"Answer from text-davinci-003: {response[\"choices\"][0][\"text\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64e4d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae464f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
